{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3893e4b-603e-4222-ac25-a4182297eb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\8\\front.jpg: 480x640 5 2s, 3 3s, 205.5ms\n",
      "Speed: 4.1ms preprocess, 205.5ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\8\\back.jpg: 480x640 8 2s, 3 3s, 263.7ms\n",
      "Speed: 0.0ms preprocess, 263.7ms inference, 10.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Unique Fruits and Their Colors:\n",
      "View: Front, Color: Blue\n",
      "View: Front, Color: Blue\n",
      "View: Front, Color: Blue\n",
      "View: Back, Color: Unknown\n",
      "View: Back, Color: Unknown\n",
      "View: Back, Color: Unknown\n",
      "View: Back, Color: Unknown\n",
      "View: Back, Color: Unknown\n",
      "View: Back, Color: Unknown\n",
      "\n",
      "Total unique fruits detected: 9\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_fruits(img_path, model, view):\n",
    "    \"\"\"Detect fruits and return their centers and dominant color along with view.\"\"\"\n",
    "    results = model.predict(img_path)[0]\n",
    "    fruits = []\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    for box in results.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "        center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
    "        fruit_roi = img[y1:y2, x1:x2]\n",
    "        color = detect_color(fruit_roi)\n",
    "        \n",
    "        fruits.append({\n",
    "            \"view\": view,\n",
    "            \"bbox\": (x1, y1, x2, y2),\n",
    "            \"color\": color\n",
    "        })\n",
    "    return fruits\n",
    "\n",
    "def detect_color(roi):\n",
    "    \"\"\"Detect the dominant color of the fruit using refined HSV ranges.\"\"\"\n",
    "    hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    avg_hsv = np.mean(hsv_roi.reshape(-1, 3), axis=0)\n",
    "    h, s, v = avg_hsv\n",
    "    \n",
    "    # Define refined HSV ranges including Purple\n",
    "    color_ranges = {\n",
    "        \"Red\": [(0, 10, 100, 255, 100, 255), (160, 180, 100, 255, 100, 255)],\n",
    "        \"Orange\": [(11, 25, 150, 255, 100, 255)],\n",
    "        \"Yellow\": [(26, 35, 150, 255, 100, 255)],\n",
    "        \"Green\": [(36, 85, 100, 255, 100, 255)],\n",
    "        \"Blue\": [(86, 125, 100, 255, 100, 255)],\n",
    "        \"Indigo\": [(126, 140, 100, 255, 100, 255)],\n",
    "        \"Violet\": [(141, 160, 100, 255, 100, 255)],\n",
    "        \"Purple\": [(125, 155, 100, 255, 50, 255)]  # Added purple\n",
    "    }\n",
    "    \n",
    "    for color, ranges in color_ranges.items():\n",
    "        for low_h, high_h, low_s, high_s, low_v, high_v in ranges:\n",
    "            if low_h <= h <= high_h and low_s <= s <= high_s and low_v <= v <= high_v:\n",
    "                return color\n",
    "    return \"Unknown\"\n",
    "\n",
    "def align_views(front_img, back_img):\n",
    "    \"\"\"Align front and back views using homography.\"\"\"\n",
    "    orb = cv2.ORB_create(nfeatures=2000)\n",
    "    kp1, des1 = orb.detectAndCompute(front_img, None)\n",
    "    kp2, des2 = orb.detectAndCompute(back_img, None)\n",
    "    \n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1, des2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)[:50]\n",
    "    \n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    \n",
    "    H, _ = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)\n",
    "    return H\n",
    "\n",
    "def count_unique_fruits(front_path, back_path, model_path):\n",
    "    \"\"\"Count unique fruits across both views based on location and color.\"\"\"\n",
    "    model = YOLO(model_path)\n",
    "    front_img = cv2.imread(front_path)\n",
    "    back_img = cv2.imread(back_path)\n",
    "    \n",
    "    front_fruits = detect_fruits(front_path, model, \"Front\")\n",
    "    back_fruits = detect_fruits(back_path, model, \"Back\")\n",
    "    \n",
    "    H = align_views(front_img, back_img)\n",
    "    \n",
    "    back_centers = np.float32([[f[\"bbox\"][:2]] for f in back_fruits])\n",
    "    transformed_centers = cv2.perspectiveTransform(back_centers, H).reshape(-1, 2) if len(back_centers) > 0 else []\n",
    "    \n",
    "    matched_back = set()\n",
    "    unique_fruits = []\n",
    "    \n",
    "    for front in front_fruits:\n",
    "        front_color = front[\"color\"]\n",
    "        matched = False\n",
    "        \n",
    "        for i, trans_center in enumerate(transformed_centers):\n",
    "            if i not in matched_back and front_color == back_fruits[i][\"color\"]:\n",
    "                matched_back.add(i)\n",
    "                matched = True\n",
    "                break\n",
    "        \n",
    "        if not matched:\n",
    "            unique_fruits.append(front)\n",
    "    \n",
    "    for i in range(len(back_fruits)):\n",
    "        if i not in matched_back:\n",
    "            unique_fruits.append(back_fruits[i])\n",
    "    \n",
    "    print(\"\\nUnique Fruits and Their Colors:\")\n",
    "    for fruit in unique_fruits:\n",
    "        print(f\"View: {fruit['view']}, Color: {fruit['color']}\")\n",
    "    \n",
    "    return len(unique_fruits)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    front_path = r'C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\8\\front.jpg'\n",
    "    back_path = r'C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\8\\back.jpg'\n",
    "    model_path = r'C:\\Users\\saart\\OneDrive\\Desktop\\best.pt'\n",
    "    \n",
    "    total_fruits = count_unique_fruits(front_path, back_path, model_path)\n",
    "    print(f\"\\nTotal unique fruits detected: {total_fruits}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9a8cfd2-f11b-44a2-ac71-7908fa45e027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\4\\Front4.jpg: 480x640 1 2, 1 3, 562.2ms\n",
      "Speed: 15.9ms preprocess, 562.2ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\4\\Back4.jpg: 480x640 1 3, 359.2ms\n",
      "Speed: 7.7ms preprocess, 359.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Unique Fruits and Their Colors:\n",
      "View: Front, Color: Unknown\n",
      "\n",
      "Total unique fruits detected: 1\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_fruits(img_path, model, view):\n",
    "    \"\"\"Detect fruits in an image, find their colors, and keep track of which view they belong to.\"\"\"\n",
    "    results = model.predict(img_path)[0]\n",
    "    fruits = []\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    for box in results.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "        center = ((x1 + x2) // 2, (y1 + y2) // 2)  # Restore center calculation\n",
    "        fruit_roi = img[y1:y2, x1:x2]  # Extract fruit area\n",
    "        color = detect_color(fruit_roi)  # Find the fruit color\n",
    "        \n",
    "        fruits.append({\n",
    "            \"view\": view,  # Store if it's from the front or back image\n",
    "            \"bbox\": (x1, y1, x2, y2),\n",
    "            \"center\": center,  # Add center back\n",
    "            \"color\": color\n",
    "        })\n",
    "    return fruits\n",
    "\n",
    "def detect_color(roi):\n",
    "    \"\"\"Find the dominant color of a fruit using HSV color space.\"\"\"\n",
    "    hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    avg_hsv = np.mean(hsv_roi.reshape(-1, 3), axis=0)  # Calculate average HSV value\n",
    "    h, s, v = avg_hsv\n",
    "    \n",
    "    # Define color ranges for detection\n",
    "    color_ranges = {\n",
    "        \"Red\": [(0, 10, 100, 255, 100, 255), (160, 180, 100, 255, 100, 255)],\n",
    "        \"Orange\": [(11, 25, 150, 255, 100, 255)],\n",
    "        \"Yellow\": [(26, 35, 150, 255, 100, 255)],\n",
    "        \"Green\": [(36, 85, 100, 255, 100, 255)],\n",
    "        \"Blue\": [(86, 125, 100, 255, 100, 255)],\n",
    "        \"Indigo\": [(126, 140, 100, 255, 100, 255)],\n",
    "        \"Violet\": [(141, 160, 100, 255, 100, 255)],\n",
    "        \"Purple\": [(125, 155, 100, 255, 50, 255)]  # Added purple\n",
    "    }\n",
    "    \n",
    "    for color, ranges in color_ranges.items():\n",
    "        for low_h, high_h, low_s, high_s, low_v, high_v in ranges:\n",
    "            if low_h <= h <= high_h and low_s <= s <= high_s and low_v <= v <= high_v:\n",
    "                return color\n",
    "    return \"Unknown\"\n",
    "\n",
    "def align_views(front_img, back_img):\n",
    "    \"\"\"Aligns the front and back views using feature matching.\"\"\"\n",
    "    orb = cv2.ORB_create(nfeatures=2000)\n",
    "    kp1, des1 = orb.detectAndCompute(front_img, None)\n",
    "    kp2, des2 = orb.detectAndCompute(back_img, None)\n",
    "    \n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1, des2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)[:50]  # Take best matches\n",
    "    \n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    \n",
    "    H, _ = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)\n",
    "    return H\n",
    "\n",
    "def count_unique_fruits(front_path, back_path, model_path):\n",
    "    \"\"\"Count the number of unique fruits seen from both front and back views.\"\"\"\n",
    "    model = YOLO(model_path)\n",
    "    front_img = cv2.imread(front_path)\n",
    "    back_img = cv2.imread(back_path)\n",
    "    \n",
    "    front_fruits = detect_fruits(front_path, model, \"Front\")\n",
    "    back_fruits = detect_fruits(back_path, model, \"Back\")\n",
    "    \n",
    "    H = align_views(front_img, back_img)\n",
    "    \n",
    "    back_centers = np.float32([[f[\"center\"]] for f in back_fruits])  # Use center instead of bbox\n",
    "    transformed_centers = cv2.perspectiveTransform(back_centers, H).reshape(-1, 2) if len(back_centers) > 0 else []\n",
    "    \n",
    "    matched_back = set()\n",
    "    unique_fruits = []\n",
    "    \n",
    "    for front in front_fruits:\n",
    "        front_center = np.array(front[\"center\"])\n",
    "        front_color = front[\"color\"]\n",
    "        matched = False\n",
    "        \n",
    "        for i, trans_center in enumerate(transformed_centers):\n",
    "            if i not in matched_back and front_color == back_fruits[i][\"color\"]:\n",
    "                dist = np.linalg.norm(front_center - trans_center)\n",
    "                if dist < 30:  # Keep reasonable distance threshold\n",
    "                    matched_back.add(i)\n",
    "                    matched = True\n",
    "                    break\n",
    "        \n",
    "        if not matched:\n",
    "            unique_fruits.append(front)\n",
    "    \n",
    "    for i in range(len(back_fruits)):\n",
    "        if i not in matched_back:\n",
    "            unique_fruits.append(back_fruits[i])\n",
    "    \n",
    "    print(\"\\nUnique Fruits and Their Colors:\")\n",
    "    for fruit in unique_fruits:\n",
    "        print(f\"View: {fruit['view']}, Color: {fruit['color']}\")\n",
    "    \n",
    "    return len(unique_fruits)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    front_path = r'C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\4\\Front4.jpg'\n",
    "    back_path = r'C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\4\\Back4.jpg'\n",
    "    model_path = r'C:\\Users\\saart\\OneDrive\\Desktop\\best.pt'\n",
    "    \n",
    "    total_fruits = count_unique_fruits(front_path, back_path, model_path)\n",
    "    print(f\"\\nTotal unique fruits detected: {total_fruits}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfd020d2-0903-485d-a058-b8e3c8fd0f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\3\\Front3.jpg: 480x640 4 1s, 1 3, 377.6ms\n",
      "Speed: 7.0ms preprocess, 377.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\3\\Back3.jpg: 480x640 4 1s, 1 3, 242.8ms\n",
      "Speed: 7.0ms preprocess, 242.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Unique Fruits and Their Colors:\n",
      "View: Front, Color: Unknown\n",
      "View: Back, Color: Green\n",
      "\n",
      "Total unique fruits detected: 2\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_fruits(img_path, model, view):\n",
    "    \"\"\"Detect fruits in an image, find their centers, colors, and keep track of which view they belong to.\"\"\"\n",
    "    results = model.predict(img_path)[0]\n",
    "    fruits = []\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    for box in results.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "        center = ((x1 + x2) // 2, (y1 + y2) // 2)  # Calculate the center of the fruit\n",
    "        fruit_roi = img[y1:y2, x1:x2]  # Extract fruit area\n",
    "        color = detect_color(fruit_roi)  # Find the fruit color\n",
    "        \n",
    "        fruits.append({\n",
    "            \"view\": view,  # Store if it's from the front or back image\n",
    "            \"center\": center,  # Store the center of the fruit\n",
    "            \"color\": color\n",
    "        })\n",
    "    return fruits\n",
    "\n",
    "def detect_color(roi):\n",
    "    \"\"\"Find the dominant color of a fruit using HSV color space.\"\"\"\n",
    "    hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    avg_hsv = np.mean(hsv_roi.reshape(-1, 3), axis=0)  # Calculate average HSV value\n",
    "    h, s, v = avg_hsv\n",
    "    \n",
    "    # Refined color ranges for detection\n",
    "    color_ranges = {\n",
    "        \"Red\": [(0, 10, 100, 255, 100, 255), (160, 180, 100, 255, 100, 255)],\n",
    "        \"Orange\": [(11, 25, 150, 255, 100, 255)],\n",
    "        \"Yellow\": [(26, 35, 150, 255, 100, 255)],\n",
    "        \"Green\": [(36, 85, 100, 255, 100, 255)],\n",
    "        \"Blue\": [(86, 125, 100, 255, 100, 255)],\n",
    "        \"Indigo\": [(126, 140, 100, 255, 100, 255)],\n",
    "        \"Violet\": [(141, 160, 100, 255, 100, 255)],\n",
    "        \"Purple\": [(125, 155, 50, 255, 50, 255)]  # Adjusted range for better purple detection\n",
    "    }\n",
    "    \n",
    "    for color, ranges in color_ranges.items():\n",
    "        for low_h, high_h, low_s, high_s, low_v, high_v in ranges:\n",
    "            if low_h <= h <= high_h and low_s <= s <= high_s and low_v <= v <= high_v:\n",
    "                return color\n",
    "    return \"Unknown\"\n",
    "\n",
    "def align_views(front_img, back_img):\n",
    "    \"\"\"Aligns the front and back views using feature matching.\"\"\"\n",
    "    orb = cv2.ORB_create(nfeatures=2000)\n",
    "    kp1, des1 = orb.detectAndCompute(front_img, None)\n",
    "    kp2, des2 = orb.detectAndCompute(back_img, None)\n",
    "    \n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1, des2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)[:50]  # Take best matches\n",
    "    \n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    \n",
    "    H, _ = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)\n",
    "    return H\n",
    "\n",
    "def count_unique_fruits(front_path, back_path, model_path):\n",
    "    \"\"\"Count the number of unique fruits seen from both front and back views.\"\"\"\n",
    "    model = YOLO(model_path)\n",
    "    front_img = cv2.imread(front_path)\n",
    "    back_img = cv2.imread(back_path)\n",
    "    \n",
    "    front_fruits = detect_fruits(front_path, model, \"Front\")\n",
    "    back_fruits = detect_fruits(back_path, model, \"Back\")\n",
    "    \n",
    "    H = align_views(front_img, back_img)\n",
    "    \n",
    "    back_centers = np.float32([fruit[\"center\"] for fruit in back_fruits]).reshape(-1, 1, 2)\n",
    "    transformed_centers = cv2.perspectiveTransform(back_centers, H).reshape(-1, 2) if len(back_centers) > 0 else []\n",
    "    \n",
    "    matched_back = set()\n",
    "    unique_fruits = []\n",
    "    \n",
    "    for front in front_fruits:\n",
    "        front_color = front[\"color\"]\n",
    "        matched = False\n",
    "        \n",
    "        for i, trans_center in enumerate(transformed_centers):\n",
    "            if i not in matched_back and front_color == back_fruits[i][\"color\"]:\n",
    "                matched_back.add(i)\n",
    "                matched = True\n",
    "                break\n",
    "        \n",
    "        if not matched:\n",
    "            unique_fruits.append(front)\n",
    "    \n",
    "    for i in range(len(back_fruits)):\n",
    "        if i not in matched_back:\n",
    "            unique_fruits.append(back_fruits[i])\n",
    "    \n",
    "    print(\"\\nUnique Fruits and Their Colors:\")\n",
    "    for fruit in unique_fruits:\n",
    "        print(f\"View: {fruit['view']}, Color: {fruit['color']}\")\n",
    "    \n",
    "    return len(unique_fruits)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    front_path = r'C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\3\\Front3.jpg'\n",
    "    back_path = r'C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\3\\Back3.jpg'\n",
    "    model_path = r'C:\\Users\\saart\\OneDrive\\Desktop\\best.pt'\n",
    "    \n",
    "    total_fruits = count_unique_fruits(front_path, back_path, model_path)\n",
    "    print(f\"\\nTotal unique fruits detected: {total_fruits}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7a6c3b0-cf6f-4cc2-b912-32c0b7697fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\4\\Front4.jpg: 480x640 1 2, 1 3, 451.0ms\n",
      "Speed: 7.6ms preprocess, 451.0ms inference, 7.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\4\\Back4.jpg: 480x640 1 3, 400.4ms\n",
      "Speed: 8.1ms preprocess, 400.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Unique Fruits and Their Colors:\n",
      "View: Front, Color: Purple\n",
      "\n",
      "Total unique fruits detected: 1\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_fruits(img_path, model, view):\n",
    "    \"\"\"Detect fruits in an image, find their centers, colors, and keep track of which view they belong to.\"\"\"\n",
    "    results = model.predict(img_path)[0]\n",
    "    fruits = []\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    for box in results.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "        center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
    "        fruit_roi = img[y1:y2, x1:x2]\n",
    "        color = detect_color(fruit_roi)\n",
    "        \n",
    "        fruits.append({\n",
    "            \"view\": view,\n",
    "            \"center\": center,\n",
    "            \"color\": color\n",
    "        })\n",
    "    return fruits\n",
    "\n",
    "def detect_color(roi):\n",
    "    \"\"\"Find the dominant color using HSV masking and morphological operations.\"\"\"\n",
    "    hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Define color ranges with HSV values\n",
    "    color_ranges = {\n",
    "        \"Red\": [\n",
    "            ([0, 100, 100], [10, 255, 255]),\n",
    "            ([160, 100, 100], [180, 255, 255])\n",
    "        ],\n",
    "        \"Orange\": [\n",
    "            ([11, 150, 100], [25, 255, 255])\n",
    "        ],\n",
    "        \"Yellow\": [\n",
    "            ([26, 150, 100], [35, 255, 255])\n",
    "        ],\n",
    "        \"Green\": [\n",
    "            ([36, 100, 100], [85, 255, 255])\n",
    "        ],\n",
    "        \"Blue\": [\n",
    "            ([86, 100, 100], [124, 255, 255])\n",
    "        ],\n",
    "        \"Purple\": [\n",
    "            ([125, 50, 50], [159, 255, 255])\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    max_pixels = 0\n",
    "    dominant_color = \"Unknown\"\n",
    "    \n",
    "    for color, ranges in color_ranges.items():\n",
    "        mask = np.zeros(hsv_roi.shape[:2], dtype=np.uint8)\n",
    "        \n",
    "        # Combine all ranges for the color\n",
    "        for (lower, upper) in ranges:\n",
    "            lower = np.array(lower, dtype=np.uint8)\n",
    "            upper = np.array(upper, dtype=np.uint8)\n",
    "            mask |= cv2.inRange(hsv_roi, lower, upper)\n",
    "        \n",
    "        # Clean up the mask\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "        \n",
    "        # Calculate percentage of color pixels\n",
    "        pixel_count = cv2.countNonZero(mask)\n",
    "        if pixel_count > max_pixels and pixel_count > 0.1 * mask.size:\n",
    "            max_pixels = pixel_count\n",
    "            dominant_color = color\n",
    "            \n",
    "    return dominant_color\n",
    "\n",
    "# Rest of the code remains unchanged\n",
    "def align_views(front_img, back_img):\n",
    "    \"\"\"Aligns the front and back views using feature matching.\"\"\"\n",
    "    orb = cv2.ORB_create(nfeatures=2000)\n",
    "    kp1, des1 = orb.detectAndCompute(front_img, None)\n",
    "    kp2, des2 = orb.detectAndCompute(back_img, None)\n",
    "    \n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1, des2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)[:50]\n",
    "    \n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    \n",
    "    H, _ = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)\n",
    "    return H\n",
    "\n",
    "def count_unique_fruits(front_path, back_path, model_path):\n",
    "    \"\"\"Count the number of unique fruits seen from both front and back views.\"\"\"\n",
    "    model = YOLO(model_path)\n",
    "    front_img = cv2.imread(front_path)\n",
    "    back_img = cv2.imread(back_path)\n",
    "    \n",
    "    front_fruits = detect_fruits(front_path, model, \"Front\")\n",
    "    back_fruits = detect_fruits(back_path, model, \"Back\")\n",
    "    \n",
    "    H = align_views(front_img, back_img)\n",
    "    \n",
    "    back_centers = np.float32([fruit[\"center\"] for fruit in back_fruits]).reshape(-1, 1, 2)\n",
    "    transformed_centers = cv2.perspectiveTransform(back_centers, H).reshape(-1, 2) if len(back_centers) > 0 else []\n",
    "    \n",
    "    matched_back = set()\n",
    "    unique_fruits = []\n",
    "    \n",
    "    for front in front_fruits:\n",
    "        front_color = front[\"color\"]\n",
    "        matched = False\n",
    "        \n",
    "        for i, trans_center in enumerate(transformed_centers):\n",
    "            if i not in matched_back and front_color == back_fruits[i][\"color\"]:\n",
    "                matched_back.add(i)\n",
    "                matched = True\n",
    "                break\n",
    "        \n",
    "        if not matched:\n",
    "            unique_fruits.append(front)\n",
    "    \n",
    "    for i in range(len(back_fruits)):\n",
    "        if i not in matched_back:\n",
    "            unique_fruits.append(back_fruits[i])\n",
    "    \n",
    "    print(\"\\nUnique Fruits and Their Colors:\")\n",
    "    for fruit in unique_fruits:\n",
    "        print(f\"View: {fruit['view']}, Color: {fruit['color']}\")\n",
    "    \n",
    "    return len(unique_fruits)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    front_path = r'C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\4\\Front4.jpg'\n",
    "    back_path = r'C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\4\\Back4.jpg'\n",
    "    model_path = r'C:\\Users\\saart\\OneDrive\\Desktop\\best.pt'\n",
    "    \n",
    "    total_fruits = count_unique_fruits(front_path, back_path, model_path)\n",
    "    print(f\"\\nTotal unique fruits detected: {total_fruits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2083da8-0201-4c9c-b883-708ba75511a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\5\\Front5.jpg: 480x640 8 1s, 3 3s, 480.2ms\n",
      "Speed: 6.5ms preprocess, 480.2ms inference, 8.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\5\\Back5.jpg: 480x640 7 1s, 3 3s, 502.2ms\n",
      "Speed: 6.5ms preprocess, 502.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Unique Fruits and Their Colors:\n",
      "View: Front, Color: Yellow\n",
      "\n",
      "Total unique fruits detected: 1\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_fruits(img_path, model, view):\n",
    "    \"\"\"Detect fruits in an image, find their centers, colors, and keep track of which view they belong to.\"\"\"\n",
    "    results = model.predict(img_path)[0]\n",
    "    fruits = []\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    for box in results.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "        center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
    "        fruit_roi = img[y1:y2, x1:x2]\n",
    "        color = detect_color(fruit_roi)\n",
    "        \n",
    "        fruits.append({\n",
    "            \"view\": view,\n",
    "            \"center\": center,\n",
    "            \"color\": color\n",
    "        })\n",
    "    return fruits\n",
    "\n",
    "def detect_color(roi):\n",
    "    \"\"\"Find the dominant color using HSV masking and morphological operations.\"\"\"\n",
    "    hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Define color ranges with HSV values\n",
    "    color_ranges = {\n",
    "        \"Red\": [\n",
    "            ([0, 100, 100], [10, 255, 255]),\n",
    "            ([160, 100, 100], [180, 255, 255])\n",
    "        ],\n",
    "        \"Orange\": [\n",
    "            ([11, 150, 100], [25, 255, 255])\n",
    "        ],\n",
    "        \"Yellow\": [\n",
    "            ([26, 150, 100], [35, 255, 255])\n",
    "        ],\n",
    "        \"Green\": [\n",
    "            ([36, 100, 100], [85, 255, 255])\n",
    "        ],\n",
    "        \"Blue\": [\n",
    "            ([86, 100, 100], [124, 255, 255])\n",
    "        ],\n",
    "        \"Purple\": [\n",
    "            ([125, 50, 50], [159, 255, 255])\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    max_pixels = 0\n",
    "    dominant_color = \"Unknown\"\n",
    "    \n",
    "    for color, ranges in color_ranges.items():\n",
    "        mask = np.zeros(hsv_roi.shape[:2], dtype=np.uint8)\n",
    "        \n",
    "        # Combine all ranges for the color\n",
    "        for (lower, upper) in ranges:\n",
    "            lower = np.array(lower, dtype=np.uint8)\n",
    "            upper = np.array(upper, dtype=np.uint8)\n",
    "            mask |= cv2.inRange(hsv_roi, lower, upper)\n",
    "        \n",
    "        # Clean up the mask\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "        \n",
    "        # Calculate percentage of color pixels\n",
    "        pixel_count = cv2.countNonZero(mask)\n",
    "        if pixel_count > max_pixels and pixel_count > 0.1 * mask.size:\n",
    "            max_pixels = pixel_count\n",
    "            dominant_color = color\n",
    "            \n",
    "    return dominant_color\n",
    "\n",
    "# Rest of the code remains unchanged\n",
    "def align_views(front_img, back_img):\n",
    "    \"\"\"Aligns the front and back views using feature matching.\"\"\"\n",
    "    orb = cv2.ORB_create(nfeatures=2000)\n",
    "    kp1, des1 = orb.detectAndCompute(front_img, None)\n",
    "    kp2, des2 = orb.detectAndCompute(back_img, None)\n",
    "    \n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1, des2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)[:50]\n",
    "    \n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    \n",
    "    H, _ = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)\n",
    "    return H\n",
    "\n",
    "def count_unique_fruits(front_path, back_path, model_path):\n",
    "    \"\"\"Count the number of unique fruits seen from both front and back views.\"\"\"\n",
    "    model = YOLO(model_path)\n",
    "    front_img = cv2.imread(front_path)\n",
    "    back_img = cv2.imread(back_path)\n",
    "    \n",
    "    front_fruits = detect_fruits(front_path, model, \"Front\")\n",
    "    back_fruits = detect_fruits(back_path, model, \"Back\")\n",
    "    \n",
    "    H = align_views(front_img, back_img)\n",
    "    \n",
    "    back_centers = np.float32([fruit[\"center\"] for fruit in back_fruits]).reshape(-1, 1, 2)\n",
    "    transformed_centers = cv2.perspectiveTransform(back_centers, H).reshape(-1, 2) if len(back_centers) > 0 else []\n",
    "    \n",
    "    matched_back = set()\n",
    "    unique_fruits = []\n",
    "    \n",
    "    for front in front_fruits:\n",
    "        front_color = front[\"color\"]\n",
    "        matched = False\n",
    "        \n",
    "        for i, trans_center in enumerate(transformed_centers):\n",
    "            if i not in matched_back and front_color == back_fruits[i][\"color\"]:\n",
    "                matched_back.add(i)\n",
    "                matched = True\n",
    "                break\n",
    "        \n",
    "        if not matched:\n",
    "            unique_fruits.append(front)\n",
    "    \n",
    "    for i in range(len(back_fruits)):\n",
    "        if i not in matched_back:\n",
    "            unique_fruits.append(back_fruits[i])\n",
    "    \n",
    "    print(\"\\nUnique Fruits and Their Colors:\")\n",
    "    for fruit in unique_fruits:\n",
    "        print(f\"View: {fruit['view']}, Color: {fruit['color']}\")\n",
    "    \n",
    "    return len(unique_fruits)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    front_path = r'C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\5\\Front5.jpg'\n",
    "    back_path = r'C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\5\\Back5.jpg'\n",
    "    model_path = r'C:\\Users\\saart\\OneDrive\\Desktop\\best.pt'\n",
    "    \n",
    "    total_fruits = count_unique_fruits(front_path, back_path, model_path)\n",
    "    print(f\"\\nTotal unique fruits detected: {total_fruits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f10c7e3b-80f2-4bdc-b376-50031a96dc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\8\\front.jpg: 480x640 5 2s, 3 3s, 469.5ms\n",
      "Speed: 6.5ms preprocess, 469.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\8\\back.jpg: 480x640 8 2s, 3 3s, 423.4ms\n",
      "Speed: 6.8ms preprocess, 423.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Unique Fruits and Their Colors:\n",
      "View: Front, Color: Unknown\n",
      "View: Front, Color: Unknown\n",
      "View: Back, Color: Unknown\n",
      "View: Back, Color: Unknown\n",
      "View: Back, Color: Unknown\n",
      "View: Back, Color: Unknown\n",
      "View: Back, Color: Unknown\n",
      "\n",
      "Total unique fruits detected: 7\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_fruits(img_path, model, view):\n",
    "    \"\"\"Detect fruits in an image, find their colors, and keep track of which view they belong to.\"\"\"\n",
    "    results = model.predict(img_path)[0]\n",
    "    fruits = []\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    for box in results.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "        center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
    "        fruit_roi = img[y1:y2, x1:x2]\n",
    "        color = detect_color(fruit_roi)  # Modified color detection\n",
    "        \n",
    "        fruits.append({\n",
    "            \"view\": view,\n",
    "            \"bbox\": (x1, y1, x2, y2),\n",
    "            \"center\": center,\n",
    "            \"color\": color\n",
    "        })\n",
    "    return fruits\n",
    "\n",
    "def detect_color(roi):\n",
    "    \"\"\"Find dominant color using HSV masking.\"\"\"\n",
    "    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    height, width = hsv.shape[:2]\n",
    "    \n",
    "    # Define color ranges (H_min, S_min, V_min), (H_max, S_max, V_max)\n",
    "    color_masks = {\n",
    "        \"Red\": [\n",
    "            ((0, 100, 100), (10, 255, 255)),\n",
    "            ((160, 100, 100), (180, 255, 255))\n",
    "        ],\n",
    "        \"Orange\": [((11, 150, 100), (25, 255, 255))],\n",
    "        \"Yellow\": [((26, 150, 100), (35, 255, 255))],\n",
    "        \"Green\": [((36, 100, 100), (85, 255, 255))],\n",
    "        \"Blue\": [((86, 100, 100), (124, 255, 255))],\n",
    "        \"Purple\": [((125, 50, 50), (159, 255, 255))]  # Wider purple range\n",
    "    }\n",
    "\n",
    "    dominant_color = \"Unknown\"\n",
    "    max_pixels = 0\n",
    "    \n",
    "    for color_name, ranges in color_masks.items():\n",
    "        combined_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "        \n",
    "        # Combine all ranges for the color\n",
    "        for (lower, upper) in ranges:\n",
    "            lower = np.array(lower, dtype=np.uint8)\n",
    "            upper = np.array(upper, dtype=np.uint8)\n",
    "            mask = cv2.inRange(hsv, lower, upper)\n",
    "            combined_mask = cv2.bitwise_or(combined_mask, mask)\n",
    "        \n",
    "        # Clean up the mask\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "        cleaned_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "        cleaned_mask = cv2.morphologyEx(cleaned_mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "        \n",
    "        # Count valid pixels\n",
    "        pixel_count = cv2.countNonZero(cleaned_mask)\n",
    "        if pixel_count > max_pixels and pixel_count > 0.1 * (height * width):\n",
    "            max_pixels = pixel_count\n",
    "            dominant_color = color_name\n",
    "            \n",
    "    return dominant_color\n",
    "\n",
    "def align_views(front_img, back_img):\n",
    "    \"\"\"Aligns the front and back views using feature matching.\"\"\"\n",
    "    orb = cv2.ORB_create(nfeatures=2000)\n",
    "    kp1, des1 = orb.detectAndCompute(front_img, None)\n",
    "    kp2, des2 = orb.detectAndCompute(back_img, None)\n",
    "    \n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1, des2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)[:50]  # Take best matches\n",
    "    \n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    \n",
    "    H, _ = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)\n",
    "    return H\n",
    "\n",
    "def count_unique_fruits(front_path, back_path, model_path):\n",
    "    \"\"\"Count the number of unique fruits seen from both front and back views.\"\"\"\n",
    "    model = YOLO(model_path)\n",
    "    front_img = cv2.imread(front_path)\n",
    "    back_img = cv2.imread(back_path)\n",
    "    \n",
    "    front_fruits = detect_fruits(front_path, model, \"Front\")\n",
    "    back_fruits = detect_fruits(back_path, model, \"Back\")\n",
    "    \n",
    "    H = align_views(front_img, back_img)\n",
    "    \n",
    "    back_centers = np.float32([[f[\"center\"]] for f in back_fruits])  # Use center instead of bbox\n",
    "    transformed_centers = cv2.perspectiveTransform(back_centers, H).reshape(-1, 2) if len(back_centers) > 0 else []\n",
    "    \n",
    "    matched_back = set()\n",
    "    unique_fruits = []\n",
    "    \n",
    "    for front in front_fruits:\n",
    "        front_center = np.array(front[\"center\"])\n",
    "        front_color = front[\"color\"]\n",
    "        matched = False\n",
    "        \n",
    "        for i, trans_center in enumerate(transformed_centers):\n",
    "            if i not in matched_back and front_color == back_fruits[i][\"color\"]:\n",
    "                dist = np.linalg.norm(front_center - trans_center)\n",
    "                if dist < 30:  # Keep reasonable distance threshold\n",
    "                    matched_back.add(i)\n",
    "                    matched = True\n",
    "                    break\n",
    "        \n",
    "        if not matched:\n",
    "            unique_fruits.append(front)\n",
    "    \n",
    "    for i in range(len(back_fruits)):\n",
    "        if i not in matched_back:\n",
    "            unique_fruits.append(back_fruits[i])\n",
    "    \n",
    "    print(\"\\nUnique Fruits and Their Colors:\")\n",
    "    for fruit in unique_fruits:\n",
    "        print(f\"View: {fruit['view']}, Color: {fruit['color']}\")\n",
    "    \n",
    "    return len(unique_fruits)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    front_path = r'C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\8\\front.jpg'\n",
    "    back_path = r'C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\8\\back.jpg'\n",
    "    model_path = r'C:\\Users\\saart\\OneDrive\\Desktop\\best.pt'\n",
    "    \n",
    "    total_fruits = count_unique_fruits(front_path, back_path, model_path)\n",
    "    print(f\"\\nTotal unique fruits detected: {total_fruits}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96f9b3df-8128-4012-b218-d6bd893c79cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\5\\Front5.jpg: 480x640 8 1s, 3 3s, 466.2ms\n",
      "Speed: 7.0ms preprocess, 466.2ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\5\\Back5.jpg: 480x640 7 1s, 3 3s, 414.3ms\n",
      "Speed: 3.5ms preprocess, 414.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Unique Fruits and Their Colors:\n",
      "View: Both, Color: Green\n",
      "View: Both, Color: Green\n",
      "View: Both, Color: Green\n",
      "View: Both, Color: Yellow\n",
      "View: Both, Color: Yellow\n",
      "View: Both, Color: Yellow\n",
      "View: Both, Color: Yellow\n",
      "View: Front, Color: Yellow\n",
      "View: Front, Color: Yellow\n",
      "View: Both, Color: Yellow\n",
      "View: Front, Color: Yellow\n",
      "View: Back, Color: Yellow\n",
      "View: Back, Color: Yellow\n",
      "\n",
      "Total unique fruits detected: 13\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_fruits(img_path, model, view):\n",
    "    \"\"\"Detect fruits in an image, find their colors, and keep track of which view they belong to.\"\"\"\n",
    "    results = model.predict(img_path)[0]\n",
    "    fruits = []\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    for box in results.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "        center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
    "        fruit_roi = img[y1:y2, x1:x2]\n",
    "        color = detect_color(fruit_roi)  # Modified color detection\n",
    "        \n",
    "        fruits.append({\n",
    "            \"view\": view,\n",
    "            \"bbox\": (x1, y1, x2, y2),\n",
    "            \"center\": center,\n",
    "            \"color\": color\n",
    "        })\n",
    "    return fruits\n",
    "\n",
    "def detect_color(roi):\n",
    "    \"\"\"Find dominant color using HSV masking.\"\"\"\n",
    "    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    height, width = hsv.shape[:2]\n",
    "    \n",
    "    # Define color ranges (H_min, S_min, V_min), (H_max, S_max, V_max)\n",
    "    color_masks = {\n",
    "        \"Red\": [\n",
    "            ((0, 100, 100), (10, 255, 255)),\n",
    "            ((160, 100, 100), (180, 255, 255))\n",
    "        ],\n",
    "        \"Orange\": [((11, 150, 100), (25, 255, 255))],\n",
    "        \"Yellow\": [((26, 150, 100), (35, 255, 255))],\n",
    "        \"Green\": [((36, 100, 100), (85, 255, 255))],\n",
    "        \"Blue\": [((86, 100, 100), (124, 255, 255))],\n",
    "        \"Purple\": [((125, 50, 50), (159, 255, 255))]  # Wider purple range\n",
    "    }\n",
    "\n",
    "    dominant_color = \"Unknown\"\n",
    "    max_pixels = 0\n",
    "    \n",
    "    for color_name, ranges in color_masks.items():\n",
    "        combined_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "        \n",
    "        # Combine all ranges for the color\n",
    "        for (lower, upper) in ranges:\n",
    "            lower = np.array(lower, dtype=np.uint8)\n",
    "            upper = np.array(upper, dtype=np.uint8)\n",
    "            mask = cv2.inRange(hsv, lower, upper)\n",
    "            combined_mask = cv2.bitwise_or(combined_mask, mask)\n",
    "        \n",
    "        # Clean up the mask\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "        cleaned_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "        cleaned_mask = cv2.morphologyEx(cleaned_mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "        \n",
    "        # Count valid pixels\n",
    "        pixel_count = cv2.countNonZero(cleaned_mask)\n",
    "        if pixel_count > max_pixels and pixel_count > 0.1 * (height * width):\n",
    "            max_pixels = pixel_count\n",
    "            dominant_color = color_name\n",
    "            \n",
    "    return dominant_color\n",
    "\n",
    "def align_views(front_img, back_img):\n",
    "    \"\"\"Aligns the front and back views using feature matching.\"\"\"\n",
    "    orb = cv2.ORB_create(nfeatures=2000)\n",
    "    kp1, des1 = orb.detectAndCompute(front_img, None)\n",
    "    kp2, des2 = orb.detectAndCompute(back_img, None)\n",
    "    \n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1, des2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)[:50]  # Take best matches\n",
    "    \n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    \n",
    "    H, _ = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)\n",
    "    return H\n",
    "\n",
    "def count_unique_fruits(front_path, back_path, model_path):\n",
    "    \"\"\"Count the number of unique fruits seen from both front and back views.\"\"\"\n",
    "    model = YOLO(model_path)\n",
    "    front_img = cv2.imread(front_path)\n",
    "    back_img = cv2.imread(back_path)\n",
    "    \n",
    "    front_fruits = detect_fruits(front_path, model, \"Front\")\n",
    "    back_fruits = detect_fruits(back_path, model, \"Back\")\n",
    "    \n",
    "    H = align_views(front_img, back_img)\n",
    "    \n",
    "    back_centers = np.float32([[f[\"center\"]] for f in back_fruits])  # Use center instead of bbox\n",
    "    transformed_centers = cv2.perspectiveTransform(back_centers, H).reshape(-1, 2) if len(back_centers) > 0 else []\n",
    "    \n",
    "    matched_back = set()\n",
    "    unique_fruits = []\n",
    "    \n",
    "    for front in front_fruits:\n",
    "        front_center = np.array(front[\"center\"])\n",
    "        front_color = front[\"color\"]\n",
    "        matched = False\n",
    "        \n",
    "        for i, trans_center in enumerate(transformed_centers):\n",
    "            if i not in matched_back and front_color == back_fruits[i][\"color\"]:\n",
    "                dist = np.linalg.norm(front_center - trans_center)\n",
    "                if dist < 30:  # Keep reasonable distance threshold\n",
    "                    matched_back.add(i)\n",
    "                    matched = True\n",
    "                    unique_fruits.append({\"view\": \"Both\", \"color\": front_color})\n",
    "                    break\n",
    "        \n",
    "        if not matched:\n",
    "            unique_fruits.append(front)\n",
    "    \n",
    "    for i in range(len(back_fruits)):\n",
    "        if i not in matched_back:\n",
    "            unique_fruits.append(back_fruits[i])\n",
    "    \n",
    "    print(\"\\nUnique Fruits and Their Colors:\")\n",
    "    for fruit in unique_fruits:\n",
    "        print(f\"View: {fruit['view']}, Color: {fruit['color']}\")\n",
    "    \n",
    "    return len(unique_fruits)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    front_path = r'C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\5\\Front5.jpg'\n",
    "    back_path = r'C:\\Users\\saart\\OneDrive\\Desktop\\UAS_DTU_Round_2_Task_data\\5\\Back5.jpg'\n",
    "    model_path = r'C:\\Users\\saart\\OneDrive\\Desktop\\best.pt'\n",
    "    \n",
    "    total_fruits = count_unique_fruits(front_path, back_path, model_path)\n",
    "    print(f\"\\nTotal unique fruits detected: {total_fruits}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77200541-f46f-4387-94a6-1a5f70c08dab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
